{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552ec552",
   "metadata": {},
   "source": [
    "# SetFit for Multilabel Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7f258-5aaf-47c2-b81e-2f10fc349812",
   "metadata": {},
   "source": [
    "In this notebook, we'll try outtext classification on a multilabel dataset with SetFit.\\\n",
    "It's known to be good for few shot learning. It relies on the embeddings models to perform training using contrastive learning.\n",
    "\n",
    "It expect it to perform well in binary classification situations like our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41542e15-d211-45e9-b428-e1532c525f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giyaseddin/miniconda3/envs/text-classification-dtse-challenge/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_id = \"BAAI/bge-small-en-v1.5\"\n",
    "# model_id = \"jinaai/jina-embedding-s-en-v1\"\n",
    "# model_id = \"avsolatorio/GIST-all-MiniLM-L6-v2\"\n",
    "# model_id = \"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "# model_id = \"WhereIsAI/UAE-Large-V1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e756be8-3b60-4c86-aa1b-7ef78289b8e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31cb0b9-e212-44c8-b762-0e4dbf76c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['clean_content', 'cyber_label', 'environmental_issue'],\n",
       "        num_rows: 1008\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['clean_content', 'cyber_label', 'environmental_issue'],\n",
       "        num_rows: 252\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_df = pd.read_csv('../data/processed/clean_train.csv')\n",
    "valid_df = pd.read_csv('../data/processed/clean_valid.csv')\n",
    "\n",
    "\n",
    "# dataset = load_dataset(\"ethos\", \"multilabel\")\n",
    "\n",
    "ds_dict = {'train' : Dataset.from_pandas(train_df),\n",
    "           'valid' : Dataset.from_pandas(valid_df)}\n",
    "\n",
    "dataset = DatasetDict(ds_dict)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0eb9bc83-bf99-422c-b123-4fcaed168bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cyber_label', 'environmental_issue']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "features = dataset[\"train\"].column_names\n",
    "features.remove(\"clean_content\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c099cb8b-2ad6-4782-a3e6-574630956d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a46662ff-aa4b-49c1-9c86-c8450e6d547b",
   "metadata": {},
   "source": [
    "We encode the emotions in a single `'label'` feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9fd491-8b80-4959-adcd-630bd17f951d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1008/1008 [00:00<00:00, 29177.97 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 252/252 [00:00<00:00, 35475.75 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def encode_labels(record):\n",
    "    return {\"labels\": [record[feature] for feature in features]}\n",
    "\n",
    "\n",
    "dataset = dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc7f32d-7320-4721-9276-ec37a39d2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"valid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bd547-0e39-43ab-adf0-5f5509217020",
   "metadata": {},
   "source": [
    "Okay, now we have the dataset, let's load and train a model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7c839-1f06-4d35-aa34-6e13659db814",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8c41a",
   "metadata": {},
   "source": [
    "To train a SetFit model, we download a pretrained checkpoint from the Hub using `from_pretrained()` method associated with the `SetFitModel` class.\n",
    "\n",
    "**Note that the `multi_target_strategy` parameter here signals to both the model and the trainer to expect a multi-labelled dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33661c9d-46d3-42eb-9b15-8a2bc49d7f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "\n",
    "model = SetFitModel.from_pretrained(model_id, multi_target_strategy=\"one-vs-rest\")\n",
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e7521e-95ca-431a-8d7f-2f18e1de16ce",
   "metadata": {},
   "source": [
    "Here, we've downloaded a pretrained Sentence Transformer from the Hub and added a logistic classification head to the create the SetFit model. As indicated in the message, we need to train this model on some labeled examples. We can do so by using the `SetFitTrainer` class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44b7069-27b0-49ea-bc27-c44f94a98e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1263755/3121297490.py:4: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Applying column mapping to the training dataset\n",
      "Applying column mapping to the evaluation dataset\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1008/1008 [00:00<00:00, 21143.31 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitTrainer\n",
    "\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss_class=CosineSimilarityLoss,\n",
    "    num_iterations=5,\n",
    "    column_mapping={\"clean_content\": \"text\", \"labels\": \"label\"},\n",
    "    batch_size=3,\n",
    "    num_epochs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3e642",
   "metadata": {},
   "source": [
    "The main arguments to notice in the trainer is the following:\n",
    "\n",
    "* `loss_class`: The loss function to use for contrastive learning with the Sentence Transformer body\n",
    "* `num_iterations`: The number of text pairs to generate for contrastive learning\n",
    "* `column_mapping`: The `SetFitTrainer` expects the inputs to be found in a `text` and `label` column. This mapping automatically formats the training and evaluation datasets for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e3c5ae-c287-4936-b1ac-5eca10c7f39c",
   "metadata": {},
   "source": [
    "Now that we've created a trainer, we can train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b5a468b-2796-47c3-8907-c0147ee58dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1263755/3344212904.py:1: DeprecationWarning: `SetFitTrainer.train` does not accept keyword arguments anymore. Please provide training arguments via a `TrainingArguments` instance to the `SetFitTrainer` initialisation or the `SetFitTrainer.train` method.\n",
      "  trainer.train(max_length=256)\n",
      "***** Running training *****\n",
      "  Num unique pairs = 10080\n",
      "  Batch size = 3\n",
      "  Num epochs = 2\n",
      "  Total optimization steps = 6720\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6720' max='6720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6720/6720 16:41, Epoch 2/0]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train(max_length=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799f994",
   "metadata": {},
   "source": [
    "The final step is to compute the model's performance using the `evaluate()` method. The default metric measures 'subset accuracy', which measures the fraction of samples where we predict all labels correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453c11d0-a1e4-49c2-859a-cc70e033b4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8214285714285714}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a007d-3811-421c-94b7-f837764efcb2",
   "metadata": {},
   "source": [
    "Let's try two random and short sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e51180c-5a62-4dfa-a543-334982db2d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(\n",
    "    [\n",
    "        \"Daily cyber topics\",\n",
    "        \"This is shouldn't be be assigned any labels?\"\n",
    "    ]\n",
    ")\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebc14708-c4f6-4137-b972-ac8c257bcb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cyber_label'], []]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show predicted labels, requires you to have stored the 'features' somewhere\n",
    "[[f for f, p in zip(features, ps) if p] for ps in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24010af-dd8e-427c-b11d-e6f1d557d0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for cyber_label: 0.9325396825396826\n",
      "Classification Report for cyber_label:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96       235\n",
      "           1       0.50      0.53      0.51        17\n",
      "\n",
      "    accuracy                           0.93       252\n",
      "   macro avg       0.73      0.75      0.74       252\n",
      "weighted avg       0.93      0.93      0.93       252\n",
      "\n",
      "Accuracy for environmental_issue: 0.8690476190476191\n",
      "Classification Report for environmental_issue:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       200\n",
      "           1       0.66      0.75      0.70        52\n",
      "\n",
      "    accuracy                           0.87       252\n",
      "   macro avg       0.80      0.82      0.81       252\n",
      "weighted avg       0.88      0.87      0.87       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "X_valid = valid_df['clean_content']\n",
    "y_valid = valid_df[['cyber_label', 'environmental_issue']]\n",
    "\n",
    "y_pred = model(X_valid)\n",
    "for i, label in enumerate(['cyber_label', 'environmental_issue']):\n",
    "    print(f\"Accuracy for {label}: {accuracy_score(y_valid.iloc[:, i], y_pred[:, i])}\")\n",
    "    print(f\"Classification Report for {label}:\\n\", classification_report(y_valid.iloc[:, i], y_pred[:, i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614e264-5b6f-4168-a739-474ac1602d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a53731e204626af339a5238c341a3f8c4bfd7cb5ccdda48ca3fe8366eef4175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
